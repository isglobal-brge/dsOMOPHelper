---
title: "Chronic Obstructive Pulmonary Disease (COPD) Analysis using dsOMOP"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{02_copd}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Introduction

For this reproducibility analysis, we utilized the **Tufts Synthetic Dataset**, which consists of fully synthetic electronic health record (EHR) data representing 567,000 synthetic patients. This dataset was generated in 2021 through a collaboration between **Syntegra, Inc.** and **Tufts Medical Center**, using a deep learning transformer model. The model was trained on real-world EHR data from the **Tufts Research Data Warehouse (TRDW)**, which includes longitudinal clinical data from patients who received care at Tufts Medical Center. The Tufts Synthetic Dataset contains clinical information such as patient visits, conditions, medications, laboratory measurements, procedures, observations, and device exposures, all structured according to the OMOP Common Data Model (CDM) version 5.3.

In this analysis, we focused on identifying key predictors for chronic obstructive pulmonary disease (COPD) based on their relevance in the literature and their availability and representation in our dataset, ensuring a sufficient patient population to obtain statistically meaningful results. These variables have well-established associations with COPD:

- Tobacco use
- Vitamin D deficiency
- History of asthma
- History of rheumatoid arthritis

## Server connection

We start by establishing a connection with ISGlobal's BRGE development Opal server. This Opal server is configured to allow access to a resource with the Tufts Synthetic Dataset:

```{r server_connection}
library(DSI)
library(DSOpal)
library(dsBaseClient)
library(dsOMOPClient)
library(dsOMOPHelper)

builder <- newDSLoginBuilder()

builder$append(server="server1", 
               url="https://opal.isglobal.org/brge",
               user="administrator", 
               password="password", 
               driver = "OpalDriver")

logindata <- builder$build()
conns <- datashield.login(logins=logindata)
```

Then we create an instance of `dsOMOPHelper` to interact with the database and build our desired dataset:

```{r dsOMOPHelper_instance, warning=FALSE}
o <- ds.omop.helper(
    connections = conns,
    resource = "omop_demo.tufts", 
    symbol = "tufts"
)
```

# Dataset construction

## Variable definition

We will define the variables that will be present in our dataset. These variables include our outcome variable and the predictor variables we'll use in our generalized linear model (GLM) for COPD:

```{r define_variables}
# Outcome variable
outcome_concept_id <- 255573 # Chronic Obstructive Pulmonary Disease (COPD)

# Predictor variables
concept_list <- c(
    4005823 # Tobacco use
)

condition_list <- c(
    317009, # History of asthma
    436070, # Rheumatoid arthritis
    80809   # Vitamin D deficiency
)
```

Based on the structure of this script, we can easily change the concept IDs of the variables and re-run this script to analyze different conditions or predictors.

## Data retrieval

We use `dsOMOPHelper`'s `auto` function to retrieve the defined variables: 

```{r data_retrieval, warning=FALSE}
o$auto(
    table = "condition_occurrence", 
    concepts = c(outcome_concept_id, condition_list),
    columns = c("condition_occurrence_id") 
    # We only want the condition occurrence ID to act as a boolean indicating 
    # the presence of the condition occurrence
)

o$auto(
    table = "observation", 
    concepts = concept_list,
    columns = c("observation_id")
    # We only want the observation ID to act as a boolean indicating 
    # the presence of the observation
)
```

## Concept name matching

We need to identify the format of the concept names as they will be added to the dataset. This allows us to automate the process of identifying exact variable names based on the retrieved concept names from the database, which facilitates automation without having to manually change the variable names in the script. 

The function `custom_make_names` is used to format the concept names as they would be in the dataset:

```{r custom_make_names}
custom_make_names <- function(name) {
  name <- make.names(name)
  name <- tolower(name)
  name <- gsub("\\.", "_", name)
  name <- gsub("_+", "_", name)
  name <- gsub("^_|_$", "", name)
  return(name)
}
```

Now we can retrieve the concept lists from the database and match them to the names as we expect them to be in the dataset:

```{r concept_matching, message=FALSE}
# Retrieve the concept catalogs for condition occurrence and observation
all_concepts_condition <- o$concepts("condition_occurrence", .Machine$integer.max)$server1
all_concepts_observation <- o$concepts("observation", .Machine$integer.max)$server1

# Match the concept IDs to the concept catalogs
matched_concept_condition <- all_concepts_condition[all_concepts_condition$concept_id == outcome_concept_id, ]
matched_concepts_conditions <- all_concepts_condition[all_concepts_condition$concept_id %in% condition_list, ]
matched_concepts_observation <- all_concepts_observation[all_concepts_observation$concept_id %in% concept_list, ]
```

These will be used to automatically match the variable names in the dataset in the next step.

## Data type conversions

DataSHIELD will not transform an ID to a boolean if it is in a string format, so this process involves two steps:
1. Transforming the ID to numeric
2. Transforming the numeric ID to boolean

we have defined a function to do this automatically for every variable:

```{r convert_to_numeric_and_boolean}
convert_to_numeric_and_boolean <- function(variable_name, id_type, conns) {
  # Construct the full variable name in the format "tufts$variable_name.id_type"
  full_variable_name <- paste0("tufts$", variable_name, ".", id_type)
  # Create a new variable name for the numeric conversion
  new_numeric_name <- paste0(variable_name, "_numeric")
  
  # Convert the original variable to numeric
  ds.asNumeric(
    x.name = full_variable_name, 
    newobj = new_numeric_name, 
    datasources = conns
  )

  # Convert the numeric variable to boolean
  # True (1) if not equal to 0, False (0) otherwise
  # NA values are assigned 0
  ds.Boole(
    V1 = new_numeric_name, 
    V2 = 0, 
    Boolean.operator = "!=", 
    numeric.output = TRUE, 
    na.assign = 0, 
    newobj = variable_name
  )
}
```

Now we can apply this function to the selected variables:

```{r automatic_type_conversion}
# Get the name of the outcome variable as it will be in the dataset
outcome_variable <- custom_make_names(matched_concept_condition$concept_name)
# Perform the type conversion of the outcome variable to numeric and then to boolean
convert_to_numeric_and_boolean(outcome_variable, "condition_occurrence_id", conns)

# Loop through every recognized condition occurrence concept
for (concept in matched_concepts_conditions$concept_name) {
  # Get the exact name of the condition occurrence as it will be in the dataset
  variable_name <- custom_make_names(concept)
  
  # Perform the type conversion of the condition occurrence to numeric and then to boolean
  convert_to_numeric_and_boolean(variable_name, "condition_occurrence_id", conns)
}

# Loop through every recognized observation concept
for (concept in matched_concepts_observation$concept_name) {
  # Get the exact name of the observation as it will be in the dataset
  variable_name <- custom_make_names(concept)
  
  # Perform the type conversion of the observation to numeric and then to boolean
  convert_to_numeric_and_boolean(variable_name, "observation_id", conns)
}
```

## Create table for the GLM

We create a new table with the prepared outcome and predictors for the GLM:

```{r create_glm_table, message=FALSE}
# Get the exact name of the variables as they will be in the dataset
variable_names <- c(
  unname(sapply(matched_concepts_observation$concept_name, custom_make_names)),
  unname(sapply(matched_concepts_conditions$concept_name, custom_make_names)),
  custom_make_names(outcome_variable)
)

# Create a new table with the prepared outcome and predictors
ds.cbind(
  x = variable_names,
  DataSHIELD.checks = FALSE,
  newobj = "glm_table",
  datasources = conns
)

# We check the structure of the resulting table to ensure it has been created correctly
ds.summary("glm_table")
```

# Generalized Linear Model

We will now fit a GLM to the prepared dataset:

```{r glm}
# Define the formula for the GLM
formula <- paste0(
  "glm_table$", outcome_variable, " ~ ", 
  paste(
    c(
      paste0("glm_table$", custom_make_names(matched_concepts_observation$concept_name)),
      paste0("glm_table$", custom_make_names(matched_concepts_conditions$concept_name))
    ),
    collapse = " + "
  )
)

# Fit the GLM
ds.glm(
  formula = formula, 
  data = "glm_table", 
  family = "binomial"
)
```
